{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# FastANI tree"
      ],
      "metadata": {
        "id": "wHxcFe4UPm3T"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "uovs-EUg4lBe"
      },
      "outputs": [],
      "source": [
        "#@markdown  #Install dependencies\n",
        "!pip install biopython 2> /dev/null 1> logs.txt\n",
        "\n",
        "import os\n",
        "if not os.path.exists('./datasets'):\n",
        "  print('Instalando Datasets')\n",
        "  !wget https://ftp.ncbi.nlm.nih.gov/pub/datasets/command-line/v2/linux-amd64/datasets 2> /dev/null 1>> logs.txt\n",
        "  !chmod +x datasets\n",
        "else:\n",
        "  print('Datasets already installed...')\n",
        "\n",
        "if not os.path.exists('/content/fastANI'):\n",
        "  print(f'Instalando FastAni')\n",
        "  !wget https://github.com/ParBLiSS/FastANI/releases/download/v1.34/fastANI-linux64-v1.34.zip 2> /dev/null 1>> logs.txt\n",
        "  !unzip fastANI-linux64-v1.34.zip 2> /dev/null 1>> logs.txt\n",
        "\n",
        "print('Instalando phylip')\n",
        "!sudo apt-get install phylip 2> /dev/null 1>> logs.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # Download genomes from NCBI\n",
        "#@markdown **Input**: a _genus_ _species_ name to a space separated list of NCBI assembly accession numbers\n",
        "#get accessions or sp\n",
        "#@markdown **Set \"get_sp\" to ON** to download all the genomes from NCBI, otherwise download by accession number lsit.\n",
        "get_sp = True #@param{type:'boolean'}\n",
        "\n",
        "get_species_genomes = '' #@param {type: 'string'}\n",
        "\n",
        "#assembly level filter\n",
        "assembly_level = True #@param {type: 'boolean'}\n",
        "if assembly_level:\n",
        "  assembly_level_flag = '--assembly-level complete'\n",
        "else:\n",
        "  assembly_level_flag = \"\"\n",
        "\n",
        "#Annotated\n",
        "annotated = True #@param {type: 'boolean'}\n",
        "if annotated:\n",
        "  annotated_flag = '--annotated'\n",
        "else:\n",
        "  annotated_flag = \"\"\n",
        "\n",
        "#exclude-atypical\n",
        "exclude_atypical = True #@param {type: 'boolean'}\n",
        "if exclude_atypical:\n",
        "  exclude_atypical_flag = '--exclude-atypical'\n",
        "else:\n",
        "  exclude_atypical_flag = \"\"\n",
        "\n",
        "#refseq only\n",
        "refseq_only = True #@param {type: 'boolean'}\n",
        "if refseq_only:\n",
        "  refseq_only_flag = '--assembly-source RefSeq'\n",
        "else:\n",
        "  refseq_only_flag = \"\"\n",
        "\n",
        "\n",
        "#@markdown ### Use if you want to download an accession list\n",
        "genome_accessions = '' #@param {type: 'string'}\n",
        "genome_accessions_list = genome_accessions.split()\n",
        "\n",
        "import os, glob\n",
        "\n",
        "try:\n",
        "  if get_sp:\n",
        "    try:\n",
        "      !./datasets download genome taxon \"{get_species_genomes}\" {assembly_level_flag} {exclude_atypical_flag } {refseq_only_flag}\n",
        "      !unzip ncbi_dataset\n",
        "      genome_list = glob.glob('/content/ncbi_dataset/data/*/**/*.fna', recursive=True)\n",
        "      base_names = {os.path.basename(i).split('.')[0]:i for i in genome_list}\n",
        "      acc = [(i.split('_')[0],i.split('_')[1].split('.')[0]) for i in base_names.keys()]\n",
        "      ref_seqs = {i[1]:'_'.join(i) for i in acc if i[0] == 'GCF'}\n",
        "      genomes = set([ '_'.join(i) if i[1] not in ref_seqs else ref_seqs[i[1]] for i in acc])\n",
        "      genome_files = [ base_names[i] for i in genomes]\n",
        "      #os.remove(f'/content/ncbi_dataset.zip')\n",
        "    except:\n",
        "      print(f'Error: {get_species_genomes} not found')\n",
        "  else:\n",
        "    %mkdir /content/genomes\n",
        "    genome_files = []\n",
        "    for acc in genome_accessions_list:\n",
        "      if not os.path.exists(f'/content/genomes/{acc}.gb'):\n",
        "        print(f'Downloading {acc} genome...')\n",
        "        try:\n",
        "          #!./datasets download genome accession {acc} --include gbff --filename {acc}.zip >/dev/null 2>&1\n",
        "          !./datasets download genome accession {acc} --filename {acc}.zip >/dev/null 2>&1\n",
        "          #!unzip -o -j {acc}.zip ncbi_dataset/data/{acc}/genomic.gbff -d ./ >/dev/null 2>&1\n",
        "          !unzip -o -j {acc}.zip ncbi_dataset/data/{acc}/*.fna -d ./ >/dev/null 2>&1\n",
        "          os.remove(f'{acc}.zip')\n",
        "          gfile = glob.glob(f'{acc}*.fna')[0]\n",
        "          !mv {gfile} /content/genomes/{acc}.fna >/dev/null 2>&1\n",
        "          genome_files.append(f'/content/genomes/{acc}.fna')\n",
        "        except:\n",
        "          print(f'Error: {acc} not found')\n",
        "except:\n",
        "  print('Error: Something went wrong')\n",
        "\n"
      ],
      "metadata": {
        "id": "VaUMsIwF42xx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown #Extract info from Genbank file"
      ],
      "metadata": {
        "id": "dM0Um90kFu7D",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ###Zip and download genomes to local computer\n",
        "import os\n",
        "import shutil\n",
        "from google.colab import files\n",
        "if get_sp:\n",
        "  for gnome in genome_files:\n",
        "    shutil.copy(gnome, os.path.join('/content/',os.path.join('/content/genomes/',os.path.basename(gnome))))\n",
        "\n",
        "!zip -r /content/genomes.zip /content/genomes\n",
        "files.download(\"/content/genomes.zip\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "XAVDuGjMf3P6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Make FastANI analysis\n",
        "Slow in Colab with only two threads... for 30 genomes max...  \n",
        "This makes an all vs all comparison."
      ],
      "metadata": {
        "id": "pn-VPEzX-0QJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### Run FastANI ALL vs ALL\n",
        "#@markdown Warning: No ANI output is reported for a genome pair if ANI value is much below 80%.\n",
        "import os\n",
        "QUERY_LIST = 'query_list.txt'\n",
        "#ncpu = !nproc\n",
        "#ncpu = int(ncpu[0])\n",
        "ncpu = os.cpu_count()\n",
        "with open(QUERY_LIST,'w') as f:\n",
        "  for genome in genome_files:\n",
        "    f.write(f'{genome}\\n')\n",
        "!./fastANI --ql {QUERY_LIST} --rl {QUERY_LIST} -o fastani.out --matrix -t {ncpu}\n"
      ],
      "metadata": {
        "id": "tE_lPbfsj68A",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### Run FastANI Ref vs ALL\n",
        "#@markdown Warning: No ANI output is reported for a genome pair if ANI value is much below 80%.\n",
        "#@markdown Pleas input the REF_SEQ Assembly accession number\n",
        "import os\n",
        "\n",
        "def download_REF_genome(acc):\n",
        "  try:\n",
        "      !./datasets download genome accession {acc} --filename {acc}.zip >/dev/null 2>&1\n",
        "      !unzip -o -j {acc}.zip ncbi_dataset/data/{acc}/*.fna -d ./ >/dev/null 2>&1\n",
        "      os.remove(f'{acc}.zip')\n",
        "      gfile = glob.glob(f'{acc}*.fna')[0]\n",
        "      if not os.path.exists('/content/genomes/'):\n",
        "        os.mkdir('/content/genomes/')\n",
        "      !mv {gfile} /content/genomes/{acc}.fna >/dev/null 2>&1\n",
        "      return(f'/content/genomes/{acc}.fna')\n",
        "  except:\n",
        "    print(f'Error: {acc} not found')\n",
        "    return(False)\n",
        "\n",
        "\n",
        "REF = '' #@param {type:\"string\"}\n",
        "ref_genome = download_REF_genome(REF)\n",
        "if ref_genome:\n",
        "  print(f\"Using {ref_genome} file as reference genome...\")\n",
        "  QUERY_LIST = 'query_list.txt'\n",
        "  ncpu = os.cpu_count()\n",
        "  with open(QUERY_LIST,'w') as f:\n",
        "    for genome in genome_files:\n",
        "      f.write(f'{genome}\\n')\n",
        "  !./fastANI -q {ref_genome} --rl {QUERY_LIST} -o fastani.out -t {ncpu}\n",
        "else:\n",
        "  print('Error: Something went wrong...')"
      ],
      "metadata": {
        "id": "7SGTlwl9b0Eq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Process the results and select by ANI difference with the reference an specifed number of genomes to work with.\n",
        "\n",
        "#@markdown To download the selected genomes check the box:\n",
        "\n",
        "Download_genomes = True #@param {type:\"boolean\"}\n",
        "\n",
        "import pandas as pd\n",
        "ref_all_ANI = pd.read_table('/content/fastani.out', sep='\\t', names=['Ref','Genome','ANI','count of bidirectional fragment mappings','total query fragments'], header = None)\n",
        "ref_all_ANI.sort_values(['ANI'], ascending=False)\n",
        "ref_all_ANI['Alignment fraction'] = ref_all_ANI['count of bidirectional fragment mappings']/ref_all_ANI['total query fragments']\n",
        "alignment_fraction_filtering = True #@param {type:\"boolean\"}\n",
        "alignment_fraction = 0.8 #@param {type:\"number\"}\n",
        "if alignment_fraction_filtering:\n",
        "  ref_all_ANI = ref_all_ANI[ref_all_ANI['Alignment fraction'] >= alignment_fraction]\n",
        "\n",
        "numer_of_Sequences = 50 #@param {type:'integer'}\n",
        "one_every = int(len(ref_all_ANI)/numer_of_Sequences)\n",
        "if one_every == 0:\n",
        "  print(f'Error, less than {numer_of_Sequences} sequences...')\n",
        "else:\n",
        "  to_analyze = []\n",
        "  ref = os.path.basename(os.path.splitext(ref_genome)[0])\n",
        "  import re\n",
        "  ref = re.sub('GCA_','GCF_',ref)\n",
        "  to_analyze.append(ref)\n",
        "  for i in range(0,len(ref_all_ANI),one_every):\n",
        "    genomeACC = '_'.join(os.path.splitext(os.path.basename(ref_all_ANI.iloc[i,1]))[0].split('_')[0:2])\n",
        "    if not genomeACC in to_analyze:\n",
        "      to_analyze.append(genomeACC)\n"
      ],
      "metadata": {
        "id": "YvVwK_HZp8KQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Download selected genomes\n",
        "if not os.path.exists('/content/to_dl'):\n",
        "  %mkdir /content/to_dl\n",
        "\n",
        "genome_files = []\n",
        "for acc in to_analyze:\n",
        "  print(f'Downloading {acc} genome...')\n",
        "  try:\n",
        "    !./datasets download genome accession {acc} --include gbff --filename {acc}.zip >/dev/null 2>&1\n",
        "    !unzip -o -j {acc}.zip ncbi_dataset/data/{acc}/genomic.gbff -d ./ >/dev/null 2>&1\n",
        "    os.remove(f'{acc}.zip')\n",
        "    !mv genomic.gbff /content/to_dl/{acc}.gbff >/dev/null 2>&1\n",
        "    genome_files.append(f'/content/to_dl/{acc}.fna')\n",
        "  except:\n",
        "    print(f'Error: {acc} not found')\n",
        "\n",
        "import shutil\n",
        "import os\n",
        "from google.colab import files\n",
        "print(f'A total of {len(to_analyze)} genomes were selected.')\n",
        "\n",
        "with open('selected_genomes.csv','w') as f:\n",
        "  f.write(f'Accession number\\n')\n",
        "  for a in to_analyze:\n",
        "    f.write(f'{a}\\n')\n",
        "print('The selected accession numbers are on selected_genomes.csv file...')\n",
        "\n",
        "if Download_genomes:\n",
        "  print('Downloading genomes in zip file...')\n",
        "  !zip -r /content/genomes.zip /content/to_dl\n",
        "  files.download(\"/content/genomes.zip\")\n",
        "\n"
      ],
      "metadata": {
        "id": "HmOEYM_CA_Jt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Make FastANI UPGMA tree.\n",
        "From here, the steps are **only for all vs all** comparisons. Requiere the Similarity ANI matrix."
      ],
      "metadata": {
        "id": "kDCkERuWbi_C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### Convert to distance matrix\n",
        "#@markdown  FastANI out matrix, default value --> *fastani.out.matrix*\n",
        "fastani_out_matrix = 'fastani.out.matrix' #@param {type:'string'}\n",
        "\n",
        "!sed -e 's/\\([^/]*\\/\\)*\\([^_]*\\)_\\([^_]*\\)[^\\t]*\\(.*\\)/\\2_\\3\\4/' {fastani_out_matrix} > /content/fastani.matrix\n",
        "\n",
        "with open('/content/fastani.matrix','r') as f:\n",
        "  line_dict = {}\n",
        "  n_seqs = f.readline()\n",
        "  ids = []\n",
        "  values = []\n",
        "  for line in f:\n",
        "    line = line.strip()\n",
        "    if (len(line.split('\\t')) == 1):\n",
        "      ids.append(line.split('.')[0])\n",
        "      values.append([''])\n",
        "    else:\n",
        "      id_simil_list =line.split('\\t')\n",
        "      size = len(id_simil_list)\n",
        "      simil_list = id_simil_list[1:size]\n",
        "      simil_list = [float(i) for i in simil_list]\n",
        "      simil_list = [str((100 - i)/100) for i in simil_list]\n",
        "      ids.append(id_simil_list[0].split('.')[0])\n",
        "      values.append(simil_list)\n",
        "\n",
        "#generate dist matrix\n",
        "with open('dist.matrix','w') as f:\n",
        "  f.write(f'\\t{n_seqs}')\n",
        "  for k,v in zip(list(range(len(ids))),values):\n",
        "    nl = '\\t'.join(v)\n",
        "    id = 'seq'+'0'*(10-3-len(str(k)))+str(k)\n",
        "    line = f'{id}\\t{nl}'.strip()+'\\n'\n",
        "    f.write(line)\n",
        "\n",
        "with open('id_list.txt','w') as f:\n",
        "  id_dict = {}\n",
        "  for i,v in enumerate(ids):\n",
        "    id = 'seq'+'0'*(10-3-len(str(i)))+str(i)\n",
        "    f.write(f'{id},{v}\\n')\n",
        "    id_dict[id]=v"
      ],
      "metadata": {
        "id": "2f3R5j1j5WB4",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown #Run phylip to make a newick tree file\n",
        "import os\n",
        "\n",
        "with open ('input','w') as f:\n",
        "  f.write('''dist.matrix\n",
        "N\n",
        "L\n",
        "Y''')\n",
        "if os.path.exists('outfile'):\n",
        "  os.remove('outfile')\n",
        "if os.path.exists('outtree'):\n",
        "  os.remove('outtree')\n",
        "!phylip neighbor < input > screenout\n"
      ],
      "metadata": {
        "id": "7kBMnlAuyfei",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ##Downloads information from NCBI and creates a table\n",
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "get_species_genomes = '' #@param {type: 'string'}\n",
        "\n",
        "try:\n",
        "  json_f = !./datasets summary genome taxon \"{get_species_genomes}\"\n",
        "except:\n",
        "  print('Error.. incorrect Genus and species')\n",
        "\n",
        "report_dict = json_f[0]\n",
        "report_dict = json.loads(report_dict)\n",
        "reports = report_dict[\"reports\"]\n",
        "\n",
        "#table\n",
        "ncbi_reports = pd.DataFrame(columns = ['Accession','Name','Strain','TaxID','Assembly level', 'N50', 'Genome length','SP by ANI', 'Check-M Completness', 'Proteins'])\n",
        "for genome_report in reports:\n",
        "  accession = genome_report['accession']\n",
        "  if 'organism' in genome_report:\n",
        "    if 'organism_name' in genome_report['organism']:\n",
        "      name = genome_report['organism']['organism_name']\n",
        "    else:\n",
        "      name = ''\n",
        "    if 'infraspecific_names' in genome_report['organism']:\n",
        "      if 'strain' in genome_report['organism']['infraspecific_names']:\n",
        "        strain = genome_report['organism']['infraspecific_names']['strain']\n",
        "      else:\n",
        "        strain = ''\n",
        "    if 'tax_id' in genome_report['organism']:\n",
        "      taxid = genome_report['organism']['tax_id']\n",
        "    else:\n",
        "      taxid = ''\n",
        "  else:\n",
        "    name = ''\n",
        "    strain = ''\n",
        "    taxid = ''\n",
        "  if 'assembly_info' in genome_report:\n",
        "    if 'assembly_level' in genome_report['assembly_info']:\n",
        "      assembly_level = genome_report['assembly_info']['assembly_level']\n",
        "    else:\n",
        "      assembly_level = ''\n",
        "  if 'assembly_stats' in genome_report:\n",
        "    if 'contig_n50' in genome_report['assembly_stats']:\n",
        "      n50 = genome_report['assembly_stats']['contig_n50']\n",
        "    else:\n",
        "      n50 = ''\n",
        "    if 'total_sequence_length' in genome_report['assembly_stats']:\n",
        "      genome_length = genome_report['assembly_stats']['total_sequence_length']\n",
        "    else:\n",
        "      genome_length = ''\n",
        "  if 'average_nucleotide_identity' in genome_report:\n",
        "    if 'submitted_ani_match' in genome_report['average_nucleotide_identity']:\n",
        "      if 'organism_name' in genome_report['average_nucleotide_identity']['submitted_ani_match']:\n",
        "        spbyani = genome_report['average_nucleotide_identity']['submitted_ani_match']['organism_name']\n",
        "      else:\n",
        "        spbyani = ''\n",
        "  if 'checkm_info' in genome_report:\n",
        "    if 'completeness' in genome_report['checkm_info']:\n",
        "      checkm = genome_report['checkm_info']['completeness']\n",
        "    else:\n",
        "      checkm = ''\n",
        "  if 'annotation_info' in genome_report:\n",
        "    if 'stats' in genome_report['annotation_info']:\n",
        "      if 'gene_counts' in genome_report['annotation_info']['stats']:\n",
        "        if 'protein_coding' in genome_report['annotation_info']['stats']['gene_counts']:\n",
        "          proteins = genome_report['annotation_info']['stats']['gene_counts']['protein_coding']\n",
        "        else:\n",
        "          proteins = ''\n",
        "  rep_tab = pd.DataFrame.from_records([{'Accession':accession, 'Name': name, 'Strain': strain, 'TaxID':taxid, 'Assembly level':assembly_level, 'N50':n50, 'Genome length':genome_length, 'SP by ANI':spbyani, 'Check-M Completness': checkm, 'Proteins': proteins}])\n",
        "  ncbi_reports = pd.concat([rep_tab,ncbi_reports])"
      ],
      "metadata": {
        "cellView": "form",
        "id": "PM78r99hlGQ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ##Prints NCBI summary table and exports it to csv format\n",
        "print(ncbi_reports)\n",
        "ncbi_reports.to_csv('NCBI_info.csv')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "TfEPAkA81mtS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### Reads NCBI table and generates id equivalences\n",
        "import pandas as pd\n",
        "\n",
        "id_2_dict = {}\n",
        "for i,row in ncbi_reports.iterrows():\n",
        "  acc = row['Accession'].split('.')[0]\n",
        "  if acc in id_dict.values():\n",
        "    id = [k for k,v in id_dict.items() if v == acc][0]\n",
        "    abb_gen = row['Name'].split()[0][0]\n",
        "    species = row['Name'].split()[1]\n",
        "    strain = row['Strain']\n",
        "    name = f'{abb_gen}. {species} {strain} [{acc}]'\n",
        "    id_2_dict[id] = name\n",
        "\n",
        "print(id_2_dict)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "1PH0X_sbQ9iT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown #### Correct the ids in tree\n",
        "import pandas as pd\n",
        "from Bio import Phylo\n",
        "tree = Phylo.read('/content/outtree','newick')\n",
        "for leave in tree.get_terminals():\n",
        "  if leave.name in id_2_dict.keys():\n",
        "    leave.name = id_2_dict[leave.name]\n",
        "\n",
        "Phylo.write(tree,'new_tree.nwk','newick')\n",
        "Phylo.draw_ascii(tree)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "s5-wZsbON9gX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Navigate tree and select n random sequences from each clade"
      ],
      "metadata": {
        "id": "bRMzdNgJ-uY1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### Set n = number of sequences to select\n",
        "# If the distance of the parent node is greater than a cutoff value (tree distance/tree leaves) then add genome to list.\n",
        "# else, keep going down until the distance is greater than the cut off. Add a value\n",
        "# of genomes calculated as a proportion of genomes in clade and remaining genomes...\n",
        "# prune processed clades\n",
        "try:\n",
        "  from Bio import Phylo\n",
        "except:\n",
        "  !pip install biopython 2> /dev/null 1> logs.txt\n",
        "\n",
        "#@markdown Load tree file in *newick format*\n",
        "load_tree = True #@param {type:'boolean'}\n",
        "if load_tree:\n",
        "  tree_file = '/content/new_tree.nwk' #@param {type:'string'}\n",
        "  tree = Phylo.read(tree_file,'newick')\n",
        "\n",
        "#@markdown Set the number of sequences to select\n",
        "n = 100 #@param {type: 'integer'}\n",
        "tree.ladderize\n",
        "tn = tree.count_terminals()\n",
        "tlen = tree.total_branch_length()\n",
        "average_len_per_n = tlen/(tn/2)\n",
        "#genome_files"
      ],
      "metadata": {
        "id": "dZJgEJt4RUPf",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### Initialize tree variables\n",
        "def get_parent_n(tree,n):\n",
        "  trayectory = tree.get_path(n)\n",
        "  steps = len(trayectory)\n",
        "  if steps == 0:\n",
        "    return(False)\n",
        "  elif steps == 1:\n",
        "    return(tree)\n",
        "  else:\n",
        "    return(trayectory[steps-2])\n",
        "\n",
        "i=1\n",
        "for node in tree.get_nonterminals(order='level'):\n",
        "  node.name = str(i)\n",
        "  node.nseqs = 0\n",
        "  i += 1\n",
        "\n",
        "for node in tree.get_terminals(order='level'):\n",
        "  node.nseqs = 0\n",
        "\n",
        "tree.nseqs = n\n",
        "tree.name = 'Root'\n",
        "parent=tree\n",
        "available_seqs = n\n",
        "parent_term = tn"
      ],
      "metadata": {
        "cellView": "form",
        "id": "DwnysyCtSY1b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### Select sequences based on nodes structure.\n",
        "#@markdown If a node has a child that is terminal it will be selected if it distance is less than the average distance per sequence divided by two.\n",
        "#@markdown Else only one child per node will be selected.\n",
        "for node in tree.get_nonterminals(order='level'):\n",
        "  added_seqs = 0\n",
        "  terminal_not_added = True\n",
        "  nterm = node.count_terminals()\n",
        "  #print(node.name, nterm, add_n, available_seqs)\n",
        "  if available_seqs > 2:\n",
        "    if len(node) == 2:\n",
        "      for child in node:\n",
        "        if child.is_terminal() and child.branch_length < average_len_per_n:\n",
        "          child.nseqs = 1\n",
        "          added_seqs += 1\n",
        "        elif child.is_terminal() and terminal_not_added:\n",
        "          child.nseqs = 1\n",
        "          added_seqs += 1\n",
        "          terminal_not_added = False\n",
        "  elif available_seqs == 1:\n",
        "    leave = node.get_terminals()[0]\n",
        "    leave.nseqs = 1\n",
        "    added_seqs += 1\n",
        "    node.nseqs = 0\n",
        "  available_seqs = available_seqs - added_seqs"
      ],
      "metadata": {
        "cellView": "form",
        "id": "EURz2VywS871"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### Show tree\n",
        "print(f'A total of {sum([node.nseqs for node in tree.get_terminals() if node.nseqs == 1])} sequences out of {tn} were selected. The input n was {n}.')\n",
        "\n",
        "selected_leaves = []\n",
        "for n in tree.get_terminals(order='level'):\n",
        "  if n.nseqs == 1:\n",
        "    n.color = 'blue'\n",
        "    selected_leaves.append(n.name)\n",
        "\n",
        "Phylo.draw(tree)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "N1lMAjgvp-rb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ###Export selected accession numbers for analysis\n",
        "import os\n",
        "selected_leaves_acc = [ l.split('[')[1].split(']')[0] for l in selected_leaves ]\n",
        "selected_id_list = [ g for g in genome_files if os.path.basename(g).split('.')[0] in selected_leaves_acc]\n",
        "\n",
        "with open('selected_files.txt','w+') as f:\n",
        "  for sid in selected_id_list:\n",
        "    f.write(f'{sid}\\n')"
      ],
      "metadata": {
        "id": "zpYMCTqCm6Yf",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}